use std::collections::HashMap;
use regex::Regex;
use lazy_static::lazy_static;

lazy_static! {
    static ref TAG_REGEX: Regex = Regex::new(r"(?:^|\s)([#@][a-z–∞-—è—ë0-9_-]+)").unwrap();
    static ref WORD_REGEX: Regex = Regex::new(r"([a-z–∞-—è—ë0-9_-]{3,})").unwrap();
}

#[derive(Default)]
pub struct Indexer {
    word_index: HashMap<String, u32>,
    tag_index: HashMap<String, u32>,
    phrase_index: HashMap<String, u32>,
    templates: HashMap<String, Vec<String>>,
}

impl Indexer {
    pub fn new() -> Self {
        let mut indexer = Self::default();
        indexer.init_templates();
        indexer
    }

    fn init_templates(&mut self) {
        // –®–∞–±–ª–æ–Ω—ã –¥–ª—è —Å–ø–∏—Å–∫–æ–≤
        self.templates.insert("—Å–ø–∏—Å–æ–∫".to_string(), vec![
            "- [ ] ".to_string(),
            "- [ ] - ".to_string(),
            "1. ".to_string(),
        ]);

        // –®–∞–±–ª–æ–Ω—ã –¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
        self.templates.insert("–∑–∞–≥–æ–ª–æ–≤–æ–∫".to_string(), vec![
            "# ".to_string(),
            "## ".to_string(),
            "### ".to_string(),
        ]);

        // –®–∞–±–ª–æ–Ω—ã –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
        self.templates.insert("–∂–∏—Ä–Ω—ã–π".to_string(), vec![
            "**".to_string(),
        ]);

        self.templates.insert("–∫—É—Ä—Å–∏–≤".to_string(), vec![
            "*".to_string(),
        ]);

        self.templates.insert("–∫–æ–¥".to_string(), vec![
            "`".to_string(),
            "```".to_string(),
        ]);

        // –®–∞–±–ª–æ–Ω—ã –¥–ª—è —Ç–∞–±–ª–∏—Ü
        self.templates.insert("—Ç–∞–±–ª–∏—Ü–∞".to_string(), vec![
            "| | |\n| --- | --- |\n| | |".to_string(),
        ]);

        // –®–∞–±–ª–æ–Ω—ã –¥–ª—è —Ü–∏—Ç–∞—Ç
        self.templates.insert("—Ü–∏—Ç–∞—Ç–∞".to_string(), vec![
            "> ".to_string(),
        ]);

        // –®–∞–±–ª–æ–Ω—ã –¥–ª—è —Å—Å—ã–ª–æ–∫
        self.templates.insert("—Å—Å—ã–ª–∫–∞".to_string(), vec![
            "[—Ç–µ–∫—Å—Ç](url)".to_string(),
        ]);

        // –®–∞–±–ª–æ–Ω—ã –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
        self.templates.insert("–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ".to_string(), vec![
            "![alt](url)".to_string(),
        ]);

        // –®–∞–±–ª–æ–Ω—ã –¥–ª—è –∑–∞–¥–∞—á
        self.templates.insert("–∑–∞–¥–∞—á–∞".to_string(), vec![
            "- [ ] ".to_string(),
        ]);

        // –®–∞–±–ª–æ–Ω—ã –¥–ª—è –∑–∞–º–µ—Ç–æ–∫
        self.templates.insert("–∑–∞–º–µ—Ç–∫–∞".to_string(), vec![
            "> üí° ".to_string(),
            "> üìù ".to_string(),
            "> ‚ö†Ô∏è ".to_string(),
        ]);
    }

    pub fn index_content(&mut self, content: &str) {
        // –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ç–µ–≥–∏
        for cap in TAG_REGEX.captures_iter(content) {
            if let Some(tag) = cap.get(1) {
                let tag = tag.as_str().to_lowercase();
                *self.tag_index.entry(tag).or_insert(0) += 1;
            }
        }

        // –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Å–ª–æ–≤–∞
        for cap in WORD_REGEX.captures_iter(content) {
            if let Some(word) = cap.get(1) {
                let word = word.as_str().to_lowercase();
                if word.len() >= 3 {
                    *self.word_index.entry(word).or_insert(0) += 1;
                }
            }
        }

        // –ò–Ω–¥–µ–∫—Å–∏—Ä—É–µ–º —Ñ—Ä–∞–∑—ã (2-3 —Å–ª–æ–≤–∞ –ø–æ–¥—Ä—è–¥)
        let words: Vec<&str> = content.split_whitespace().collect();
        for i in 0..words.len() {
            if i + 1 < words.len() {
                let word1 = words[i].to_lowercase();
                let word2 = words[i + 1].to_lowercase();
                if word1.len() >= 3 && word2.len() >= 3 {
                    let phrase = format!("{} {}", word1, word2);
                    *self.phrase_index.entry(phrase).or_insert(0) += 1;
                }
            }
            if i + 2 < words.len() {
                let word1 = words[i].to_lowercase();
                let word2 = words[i + 1].to_lowercase();
                let word3 = words[i + 2].to_lowercase();
                if word1.len() >= 3 && word2.len() >= 3 && word3.len() >= 3 {
                    let phrase = format!("{} {} {}", word1, word2, word3);
                    *self.phrase_index.entry(phrase).or_insert(0) += 1;
                }
            }
        }
    }

    pub fn find_completions(&self, prefix: &str, limit: usize) -> Vec<(String, String, u32)> {
        if prefix.len() < 2 {
            return Vec::new();
        }

        let prefix = prefix.to_lowercase();
        let mut results = Vec::new();

        // –ü—Ä–æ–≤–µ—Ä—è–µ–º —à–∞–±–ª–æ–Ω—ã
        for (template_name, templates) in &self.templates {
            if template_name.contains(&prefix) {
                for template in templates {
                    results.push((template.clone(), "template".to_string(), 100));
                }
            }
        }

        // –ï—Å–ª–∏ –ø—Ä–µ—Ñ–∏–∫—Å –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å @ –∏–ª–∏ #, –∏—â–µ–º –ø–æ —Ç–µ–≥–∞–º
        if prefix.starts_with('@') || prefix.starts_with('#') {
            for (tag, count) in &self.tag_index {
                if tag.starts_with(&prefix) {
                    results.push((tag.clone(), "tag".to_string(), *count));
                }
            }
        } else {
            // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –ø—Ä–æ–±–µ–ª –≤ –ø—Ä–µ—Ñ–∏–∫—Å–µ
            if prefix.contains(' ') {
                // –ò—â–µ–º –ø–æ —Ñ—Ä–∞–∑–∞–º
                for (phrase, count) in &self.phrase_index {
                    if phrase.starts_with(&prefix) {
                        results.push((phrase.clone(), "phrase".to_string(), *count));
                    }
                }
            } else {
                // –ò—â–µ–º –ø–æ —Å–ª–æ–≤–∞–º
                for (word, count) in &self.word_index {
                    if word.starts_with(&prefix) {
                        results.push((word.clone(), "word".to_string(), *count));
                    }
                }
            }
        }

        // –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —á–∞—Å—Ç–æ—Ç–µ –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        results.sort_by(|a, b| b.2.cmp(&a.2));
        results.truncate(limit);

        results
    }

    pub fn clear(&mut self) {
        self.word_index.clear();
        self.tag_index.clear();
        self.phrase_index.clear();
    }
} 